{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9e18c9-2c55-432d-8ae3-35b518c4a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d23eb1-aa20-4057-b1f6-5cfba744bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_Galaxy_ZooAUG  = pd.read_csv ('D:/nir/gc/GalaxyZoo1_DR_table2.csv ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dfe42b-7766-4f51-b5d6-80ce617180bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, download_path, galaxy_data):\n",
    "        self.download_path = download_path\n",
    "        self.galaxy_data = galaxy_data\n",
    "\n",
    "    def parse_coordinates(self, coordinate_str):\n",
    "        parts = coordinate_str.split(':')\n",
    "        return \"_\".join(parts)\n",
    "\n",
    "    def getDeg(self, hours, minutes, seconds):\n",
    "        DegSeconds = seconds * 15\n",
    "        DegMinutes = minutes * 15\n",
    "        Deg = hours * 15\n",
    "        return Deg + 0.0167 * DegMinutes + 0.000278 * DegSeconds\n",
    "\n",
    "    def sign(self, value):\n",
    "        if value >= 0:\n",
    "            return 1\n",
    "        return -1\n",
    "\n",
    "    def load_image(self, RA, DEC, spiral, elliptical, uncertain):\n",
    "        path = self.download_path\n",
    "        RA_str = self.parse_coordinates(str(RA))\n",
    "        DEC_str = self.parse_coordinates(str(DEC))\n",
    "        \n",
    "        galaxy_type = \"\"\n",
    "        if spiral == 1:\n",
    "            galaxy_type = \"SPIRAL\"\n",
    "        elif elliptical == 1:\n",
    "            galaxy_type = \"ELLIPTICAL\"\n",
    "        elif uncertain == 1:\n",
    "            galaxy_type = \"UNCERTAIN\"\n",
    "        \n",
    "        filename = f\"{RA_str}_{DEC_str}_{galaxy_type}.jpg\"\n",
    "        full_path = os.path.join(path, re.sub(r':', '_', filename))\n",
    "\n",
    "        resource = urlopen(\"https://skyserver.sdss.org/dr16/SkyServerWS/ImgCutout/getjpeg?TaskName=Skyserver.Chart.ShowNearest&ra=\" + str(RA) + \"&dec=\" + str(DEC) + \"&scale=0.2&opt=\")\n",
    "        \n",
    "        with open(full_path, 'wb') as outFile:\n",
    "            outFile.write(resource.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f27e58-9970-4e69-89b2-38914cff9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spirals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['SPIRAL'] == 1].head(14000)\n",
    "ellipticals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['ELLIPTICAL'] == 1].head(14000)\n",
    "uncertains = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['UNCERTAIN'] == 1].head(14000)\n",
    "\n",
    "scraper = ImageLoader(download_path='D:/nir/gc/imagesBalance', galaxy_data=catalog_Galaxy_ZooAUG)\n",
    "\n",
    "for index, galaxy in spirals.iterrows():\n",
    "    try:\n",
    "        scraper.load_image(galaxy['RA'], galaxy['DEC'], 1, 0, 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке изображения для галактики {index}: {e}\")\n",
    "\n",
    "\n",
    "for index, galaxy in uncertains.iterrows():\n",
    "    try:\n",
    "        scraper.load_image(galaxy['RA'], galaxy['DEC'], 0, 0, 1)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке изображения для галактики {index}: {e}\")\n",
    "\n",
    "\n",
    "for index, galaxy in ellipticals.iterrows():\n",
    "    try:\n",
    "        scraper.load_image(galaxy['RA'], galaxy['DEC'], 0, 1, 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке изображения для галактики {index}: {e}\")\n",
    "\n",
    "print(f\"Загрузка завершена\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431a28e-3ab1-4da0-a75e-b23042634561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base_path = 'D:/nir/gc/imagesBalance'\n",
    "output_dir = 'D:/nir/gc/sorted_images'\n",
    "\n",
    "\n",
    "class_dirs = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
    "for class_dir in class_dirs:\n",
    "    os.makedirs(os.path.join(output_dir, class_dir), exist_ok=True)\n",
    "\n",
    "\n",
    "for filename in os.listdir(base_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        src_path = os.path.join(base_path, filename) \n",
    "\n",
    "        if 'SPIRAL' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'SPIRAL', filename)\n",
    "        elif 'ELLIPTICAL' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'ELLIPTICAL', filename)\n",
    "        elif 'UNCERTAIN' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'UNCERTAIN', filename)\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "        shutil.copy(src_path, dst_path) \n",
    "\n",
    "print(\"Копирование завершено\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d3f42-f295-41cd-b632-03b4ddeec6c1",
   "metadata": {},
   "source": [
    "# Создание аугментированных наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5f8a8-b500-410d-af49-d57a6f48a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "\n",
    "base_path = r'D:\\nir\\gc\\sorted_images42000' \n",
    "output_base = r'D:\\nir\\gc\\augmented_dataT' \n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
    "\n",
    "\n",
    "augmentations = {\n",
    "    \"original_21000\": (\"orig_\", lambda img: img),\n",
    "    \"noise_21000\": (\"noise_\", lambda img: Image.fromarray((random_noise(np.array(img), mode='gaussian', var=0.01) * 255).astype(np.uint8))),\n",
    "    \"horizontal_flip_21000\": (\"hflip_\", lambda img: img.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "    \"vertical_flip_21000\": (\"vflip_\", lambda img: img.transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "    \"rotate_90_cw_21000\": (\"rot90cw_\", lambda img: img.rotate(-90, expand=True)),\n",
    "    \"rotate_90_ccw_21000\": (\"rot90ccw_\", lambda img: img.rotate(90, expand=True)),\n",
    "    \"rotate_15_cw_21000\": (\"rot15cw_\", lambda img: img.rotate(-15, expand=True)),\n",
    "    \"rotate_15_ccw_21000\": (\"rot15ccw_\", lambda img: img.rotate(15, expand=True))\n",
    "}\n",
    "\n",
    "# Создание папок\n",
    "for aug_name in augmentations:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_base, aug_name, category), exist_ok=True)\n",
    "\n",
    "# Применение аугментации и сохранение файлов\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    files = [f for f in os.listdir(category_path) if f.endswith('.jpg')][:7000]  \n",
    "\n",
    "    for file_name in files:\n",
    "        img_path = os.path.join(category_path, file_name)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        for aug_name, (prefix, aug_func) in augmentations.items():\n",
    "            aug_img = aug_func(img)\n",
    "\n",
    "            base_name, ext = os.path.splitext(file_name)  \n",
    "            new_file_name = f\"{prefix}{base_name}{ext}\" \n",
    "            save_path = os.path.join(output_base, aug_name, category, new_file_name)\n",
    "            aug_img.save(save_path)\n",
    "\n",
    "print(\"Создание аугментированных наборов завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba062ea-59b1-463c-bfad-e1397dfbaef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание комбинированных папок завершено\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "original_path = r'D:\\nir\\gc\\augmented_data\\original_21000' \n",
    "augmented_base_path = r'D:\\nir\\gc\\augmented_data' \n",
    "output_base = r'D:\\nir\\gc\\final_combined_data'  \n",
    "\n",
    "combined_folders = {\n",
    "    \"original_and_noise_42000\": \"noise_21000\",\n",
    "    \"original_and_vertical_flip_42000\": \"vertical_flip_21000\",\n",
    "    \"original_and_horizontal_flip_42000\": \"horizontal_flip_21000\",\n",
    "    \"original_and_rotate_90_cw_42000\": \"rotate_90_cw_21000\",\n",
    "    \"original_and_rotate_90_ccw_42000\": \"rotate_90_ccw_21000\",\n",
    "    \"original_and_rotate_15_cw_42000\": \"rotate_15_cw_21000\",\n",
    "    \"original_and_rotate_15_ccw_42000\": \"rotate_15_ccw_21000\"\n",
    "}\n",
    "\n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
    "\n",
    "for combined_name in combined_folders:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_base, combined_name, category), exist_ok=True)\n",
    "\n",
    "for combined_name, aug_folder in combined_folders.items():\n",
    "    for category in categories:\n",
    "        orig_src = os.path.join(original_path, category)\n",
    "        aug_src = os.path.join(augmented_base_path, aug_folder, category)\n",
    "        dest_folder = os.path.join(output_base, combined_name, category)\n",
    "\n",
    "        for file_name in os.listdir(orig_src):\n",
    "            shutil.copy(os.path.join(orig_src, file_name), os.path.join(dest_folder, file_name))\n",
    "\n",
    "        for file_name in os.listdir(aug_src):\n",
    "            shutil.copy(os.path.join(aug_src, file_name), os.path.join(dest_folder, file_name))\n",
    "\n",
    "print(\"Создание комбинированных папок завершено\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05fc35e8-4e35-4702-9747-d81c4de8333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "noise: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "horizontal_flip: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "vertical_flip: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "rotate_90_cw: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "rotate_90_ccw: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "rotate_15_cw: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "rotate_15_ccw: {'SPIRAL': 10, 'ELLIPTICAL': 10, 'UNCERTAIN': 10} файлов скопировано\n",
      "ИТОГОВОЕ РАСПРЕДЕЛЕНИЕ: {'SPIRAL': 80, 'ELLIPTICAL': 80, 'UNCERTAIN': 80}\n",
      "Создание финальной папки с 42000 изображениями завершено!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "original_path = r'D:\\nir\\gc\\augmented_dataT\\original_21000'  \n",
    "augmented_base_path = r'D:\\nir\\gc\\augmented_data'  \n",
    "output_base = r'D:\\nir\\gc\\final_mixed_data_42000'  \n",
    "\n",
    "augmentations = {\n",
    "    \"original\": \"original_21000\",\n",
    "    \"noise\": \"noise_21000\",\n",
    "    \"horizontal_flip\": \"horizontal_flip_21000\",\n",
    "    \"vertical_flip\": \"vertical_flip_21000\",\n",
    "    \"rotate_90_cw\": \"rotate_90_cw_21000\",\n",
    "    \"rotate_90_ccw\": \"rotate_90_ccw_21000\",\n",
    "    \"rotate_15_cw\": \"rotate_15_cw_21000\",\n",
    "    \"rotate_15_ccw\": \"rotate_15_ccw_21000\"\n",
    "}\n",
    "\n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN']\n",
    "\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_base, category), exist_ok=True)\n",
    "\n",
    "for aug_name, folder in augmentations.items():\n",
    "    total_copied = {category: 0 for category in categories} \n",
    "\n",
    "    for category in categories:\n",
    "        src_folder = os.path.join(augmented_base_path, folder, category)\n",
    "        dest_folder = os.path.join(output_base, category)\n",
    "\n",
    "        files = [f for f in os.listdir(src_folder) if f.endswith('.jpg')][:1750]\n",
    "\n",
    "        for file_name in files:\n",
    "            shutil.copy(os.path.join(src_folder, file_name), os.path.join(dest_folder, file_name))\n",
    "            total_copied[category] += 1 \n",
    "\n",
    "    print(f\"{aug_name}: {total_copied} файлов скопировано\")\n",
    "\n",
    "final_counts = {category: len(os.listdir(os.path.join(output_base, category))) for category in categories}\n",
    "print(f\"ИТОГОВОЕ РАСПРЕДЕЛЕНИЕ: {final_counts}\")\n",
    "\n",
    "print(\"Создание финальной папки с 42000 изображениями завершено\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92446f-bc8a-4622-b32f-651841e0171d",
   "metadata": {},
   "source": [
    "# Определения оптимального количества эпох обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ebbbe-80cb-4e45-b0a7-c40b5ee20731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "DATASET_PATH = 'D:/nir/gc/sorted_images42000' \n",
    "MODEL_SAVE_PATH = 'galaxy_classifier_original.keras' \n",
    "\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Указанная директория '{DATASET_PATH}' не найдена.\")\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "training_time = (end_time - start_time) / 60  \n",
    "print(f\"\\nВремя обучения: {training_time:.2f} минут\")\n",
    "\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator, steps=val_generator.samples // BATCH_SIZE + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  \n",
    "true_classes = val_generator.classes \n",
    "class_labels = list(val_generator.class_indices.keys()) \n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"\\nОтчёт о классификации:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"\\nМодель сохранена в {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad18e6e-13a9-4149-a669-3f7256448846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a757c9e-35ef-43d4-b239-aba36e6bf0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('training_history3.pkl', 'rb') as f:\n",
    "    loaded_history_ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505713e-764d-40a0-8208-540de86f6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loaded_history_['loss'], label='Потери на обучающей выборке')\n",
    "\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Функция потерь')\n",
    "\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlim(0, 50.0)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('training_loss_plot_.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015cd876-59a3-4959-a2cd-8728c5f2c77e",
   "metadata": {},
   "source": [
    "# Модель для обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a6a6b-5460-4454-9d7b-0c54f8e15c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time  \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DATASET_PATH = 'D:/nir/gc/sorted42000' \n",
    "MODEL_SAVE_PATH = 'galaxy_classifier_original.keras' \n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Указанная директория '{DATASET_PATH}' не найдена.\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    Dense(3, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "training_time = (end_time - start_time) / 60  \n",
    "print(f\"\\nВремя обучения: {training_time:.2f} минут\")\n",
    "\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator, steps=val_generator.samples // BATCH_SIZE + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  \n",
    "true_classes = val_generator.classes  \n",
    "class_labels = list(val_generator.class_indices.keys())  \n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"\\nОтчёт о классификации:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"\\nМодель сохранена в {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391aadd8-5d3e-4257-9e8e-6c375f983391",
   "metadata": {},
   "source": [
    "# Взаимодействующие галактики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e753fa-a512-4165-80d8-79107aa83d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Спиральные галактики: 190225, с merger: 0 (0.00%)\n",
      "Эллиптические галактики: 62190, с merger: 0 (0.00%)\n",
      "Неправильные галактики: 415529, с merger: 10790 (2.60%)\n"
     ]
    }
   ],
   "source": [
    "spirals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['SPIRAL'] == 1] \n",
    "ellipticals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['ELLIPTICAL'] == 1]  \n",
    "uncertains = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['UNCERTAIN'] == 1]  \n",
    "\n",
    "def count_mergers(df):\n",
    "    return (df['P_MG'] > 0.4).sum()\n",
    "\n",
    "spiral_mergers = count_mergers(spirals)\n",
    "elliptical_mergers = count_mergers(ellipticals)\n",
    "uncertain_mergers = count_mergers(uncertains)\n",
    "\n",
    "spiral_total = len(spirals)\n",
    "elliptical_total = len(ellipticals)\n",
    "uncertain_total = len(uncertains)\n",
    "\n",
    "spiral_merger_percent = (spiral_mergers / spiral_total) * 100 if spiral_total > 0 else 0\n",
    "elliptical_merger_percent = (elliptical_mergers / elliptical_total) * 100 if elliptical_total > 0 else 0\n",
    "uncertain_merger_percent = (uncertain_mergers / uncertain_total) * 100 if uncertain_total > 0 else 0\n",
    "\n",
    "print(f\"Спиральные галактики: {spiral_total}, с merger: {spiral_mergers} ({spiral_merger_percent:.2f}%)\")\n",
    "print(f\"Эллиптические галактики: {elliptical_total}, с merger: {elliptical_mergers} ({elliptical_merger_percent:.2f}%)\")\n",
    "print(f\"Неправильные галактики: {uncertain_total}, с merger: {uncertain_mergers} ({uncertain_merger_percent:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1182192-7da9-4a1a-87b5-60c7b5cfb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, download_path, galaxy_data):\n",
    "        self.download_path = download_path\n",
    "        self.galaxy_data = galaxy_data\n",
    "\n",
    "    def parse_coordinates(self, coordinate_str):\n",
    "        parts = coordinate_str.split(':')\n",
    "        return \"_\".join(parts)\n",
    "\n",
    "    def getDeg(self, hours, minutes, seconds):\n",
    "        DegSeconds = seconds * 15\n",
    "        DegMinutes = minutes * 15\n",
    "        Deg = hours * 15\n",
    "        return Deg + 0.0167 * DegMinutes + 0.000278 * DegSeconds\n",
    "\n",
    "    def sign(self, value):\n",
    "        return 1 if value >= 0 else -1\n",
    "\n",
    "    def load_image(self, RA, DEC, spiral, elliptical, uncertain, merger):\n",
    "        path = self.download_path\n",
    "        RA_str = self.parse_coordinates(str(RA))\n",
    "        DEC_str = self.parse_coordinates(str(DEC))\n",
    "\n",
    "        # Определение типа галактики\n",
    "        galaxy_type = \"\"\n",
    "        if spiral == 1:\n",
    "            galaxy_type = \"SPIRAL\"\n",
    "        elif elliptical == 1:\n",
    "            galaxy_type = \"ELLIPTICAL\"\n",
    "        elif uncertain == 1:\n",
    "            galaxy_type = \"UNCERTAIN\"\n",
    "        elif merger == 1:\n",
    "            galaxy_type = \"MERGER\"\n",
    "\n",
    "        filename = f\"{RA_str}_{DEC_str}_{galaxy_type}.jpg\"\n",
    "        full_path = os.path.join(path, re.sub(r':', '_', filename))\n",
    "\n",
    "        try:\n",
    "            resource = urlopen(\n",
    "                f\"https://skyserver.sdss.org/dr16/SkyServerWS/ImgCutout/getjpeg?\"\n",
    "                f\"TaskName=Skyserver.Chart.ShowNearest&ra={RA}&dec={DEC}&scale=0.2&opt=\"\n",
    "            )\n",
    "\n",
    "            with open(full_path, 'wb') as outFile:\n",
    "                outFile.write(resource.read())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке изображения ({RA}, {DEC}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bce3cb-ec7a-4622-b783-7f146da990f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spirals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['SPIRAL'] == 1].head(10500)\n",
    "ellipticals = catalog_Galaxy_ZooAUG[catalog_Galaxy_ZooAUG['ELLIPTICAL'] == 1].head(10500)\n",
    "\n",
    "uncertains = catalog_Galaxy_ZooAUG[\n",
    "    (catalog_Galaxy_ZooAUG['UNCERTAIN'] == 1) & (catalog_Galaxy_ZooAUG['P_MG'] < 0.4)\n",
    "].head(10500)\n",
    "\n",
    "mergers = catalog_Galaxy_ZooAUG[\n",
    "    (catalog_Galaxy_ZooAUG['UNCERTAIN'] == 1) & (catalog_Galaxy_ZooAUG['P_MG'] > 0.4)\n",
    "].head(10500)\n",
    "\n",
    "scraper = ImageLoader(download_path='D:/nir/gc/images_with_merge', galaxy_data=catalog_Galaxy_ZooAUG)\n",
    "loaded_images = 0\n",
    "\n",
    "def load_galaxy_images(df, label, spiral, elliptical, uncertain, merger):\n",
    "    global loaded_images\n",
    "    for index, galaxy in df.iterrows():\n",
    "        try:\n",
    "            scraper.load_image(galaxy['RA'], galaxy['DEC'], spiral, elliptical, uncertain, merger)\n",
    "            loaded_images += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке изображения для галактики {index}: {e}\")\n",
    "\n",
    "    print(f\"Загружено {loaded_images} {label} галактик\")\n",
    "\n",
    "load_galaxy_images(mergers, \"взаимодействующих\", 0, 0, 0, 1)\n",
    "load_galaxy_images(uncertains, \"неправильных\", 0, 0, 1, 0)\n",
    "load_galaxy_images(spirals, \"спиральных\", 1, 0, 0, 0)\n",
    "load_galaxy_images(ellipticals, \"эллиптических\", 0, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "769f31f3-0564-4898-8044-2f250235b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Копирование завершено\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "base_path = 'D:/nir/gc/images_with_merge'\n",
    "output_dir = 'D:/nir/gc/images_merge'\n",
    "\n",
    "class_dirs = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN', 'MERGER']\n",
    "for class_dir in class_dirs:\n",
    "    os.makedirs(os.path.join(output_dir, class_dir), exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(base_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        src_path = os.path.join(base_path, filename) \n",
    "\n",
    "        if 'SPIRAL' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'SPIRAL', filename)\n",
    "        elif 'ELLIPTICAL' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'ELLIPTICAL', filename)\n",
    "        elif 'UNCERTAIN' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'UNCERTAIN', filename)\n",
    "        elif 'MERGER' in filename:\n",
    "            dst_path = os.path.join(output_dir, 'MERGER', filename)\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "        shutil.copy(src_path, dst_path) \n",
    "\n",
    "print(\"Копирование завершено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486c605-f907-4d5f-85c9-7944dd67937b",
   "metadata": {},
   "source": [
    "# Создание аугментированных наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0757531f-7587-4913-856f-a387fa02592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание аугментированных наборов завершено\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "base_path = r'D:\\nir\\gc\\images_merge' \n",
    "output_base = r'D:\\nir\\gc\\augmented_data_with_merge' \n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN', 'MERGER']\n",
    "\n",
    "augmentations = {\n",
    "    \"original_21000\": (\"orig_\", lambda img: img),\n",
    "    \"noise_21000\": (\"noise_\", lambda img: Image.fromarray((random_noise(np.array(img), mode='gaussian', var=0.01) * 255).astype(np.uint8))),\n",
    "    \"horizontal_flip_21000\": (\"hflip_\", lambda img: img.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "    \"vertical_flip_21000\": (\"vflip_\", lambda img: img.transpose(Image.FLIP_TOP_BOTTOM)),\n",
    "    \"rotate_90_cw_21000\": (\"rot90cw_\", lambda img: img.rotate(-90, expand=True)),\n",
    "    \"rotate_90_ccw_21000\": (\"rot90ccw_\", lambda img: img.rotate(90, expand=True)),\n",
    "    \"rotate_15_cw_21000\": (\"rot15cw_\", lambda img: img.rotate(-15, expand=True)),\n",
    "    \"rotate_15_ccw_21000\": (\"rot15ccw_\", lambda img: img.rotate(15, expand=True))\n",
    "}\n",
    "\n",
    "for aug_name in augmentations:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_base, aug_name, category), exist_ok=True)\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    files = [f for f in os.listdir(category_path) if f.endswith('.jpg')][:7000]  \n",
    "\n",
    "    for file_name in files:\n",
    "        img_path = os.path.join(category_path, file_name)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        for aug_name, (prefix, aug_func) in augmentations.items():\n",
    "            aug_img = aug_func(img)\n",
    "\n",
    "            base_name, ext = os.path.splitext(file_name)  \n",
    "            new_file_name = f\"{prefix}{base_name}{ext}\" \n",
    "            save_path = os.path.join(output_base, aug_name, category, new_file_name)\n",
    "            aug_img.save(save_path)\n",
    "\n",
    "print(\"Создание аугментированных наборов завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65c60197-b856-4ab3-90b6-224a0a3a3f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание комбинированных папок завершено\n"
     ]
    }
   ],
   "source": [
    "original_path = r'D:\\nir\\gc\\augmented_data_with_merge\\original_21000' \n",
    "augmented_base_path = r'D:\\nir\\gc\\augmented_data_with_merge' \n",
    "output_base = r'D:\\nir\\gc\\final_combined_data_with_merge'  \n",
    "\n",
    "combined_folders = {\n",
    "    \"original_and_noise_42000\": \"noise_21000\",\n",
    "    \"original_and_vertical_flip_42000\": \"vertical_flip_21000\",\n",
    "    \"original_and_horizontal_flip_42000\": \"horizontal_flip_21000\",\n",
    "    \"original_and_rotate_90_cw_42000\": \"rotate_90_cw_21000\",\n",
    "    \"original_and_rotate_90_ccw_42000\": \"rotate_90_ccw_21000\",\n",
    "    \"original_and_rotate_15_cw_42000\": \"rotate_15_cw_21000\",\n",
    "    \"original_and_rotate_15_ccw_42000\": \"rotate_15_ccw_21000\"\n",
    "}\n",
    "\n",
    "\n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN', 'MERGER']\n",
    "\n",
    "for combined_name in combined_folders:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_base, combined_name, category), exist_ok=True)\n",
    "\n",
    "for combined_name, aug_folder in combined_folders.items():\n",
    "    for category in categories:\n",
    "        orig_src = os.path.join(original_path, category)\n",
    "        aug_src = os.path.join(augmented_base_path, aug_folder, category)\n",
    "        dest_folder = os.path.join(output_base, combined_name, category)\n",
    "\n",
    "        for file_name in os.listdir(orig_src):\n",
    "            shutil.copy(os.path.join(orig_src, file_name), os.path.join(dest_folder, file_name))\n",
    "\n",
    "        for file_name in os.listdir(aug_src):\n",
    "            shutil.copy(os.path.join(aug_src, file_name), os.path.join(dest_folder, file_name))\n",
    "\n",
    "print(\"Создание комбинированных папок завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe1873a5-7694-44dc-b896-7b88840ca0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "noise: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "horizontal_flip: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "vertical_flip: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "rotate_90_cw: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "rotate_90_ccw: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "rotate_15_cw: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "rotate_15_ccw: {'SPIRAL': 1313, 'ELLIPTICAL': 1313, 'UNCERTAIN': 1313, 'MERGER': 1313} файлов скопировано\n",
      "ИТОГОВОЕ РАСПРЕДЕЛЕНИЕ: {'SPIRAL': 10504, 'ELLIPTICAL': 10504, 'UNCERTAIN': 10504, 'MERGER': 10504}\n",
      "Создание финальной папки с 42000 изображениями завершено\n"
     ]
    }
   ],
   "source": [
    "original_path = r'D:\\nir\\gc\\augmented_data_with_merge\\original_21000'  \n",
    "augmented_base_path = r'D:\\nir\\gc\\augmented_data_with_merge'  \n",
    "output_base = r'D:\\nir\\gc\\final_mixed_data__with_merge'  \n",
    "\n",
    "augmentations = {\n",
    "    \"original\": \"original_21000\",\n",
    "    \"noise\": \"noise_21000\",\n",
    "    \"horizontal_flip\": \"horizontal_flip_21000\",\n",
    "    \"vertical_flip\": \"vertical_flip_21000\",\n",
    "    \"rotate_90_cw\": \"rotate_90_cw_21000\",\n",
    "    \"rotate_90_ccw\": \"rotate_90_ccw_21000\",\n",
    "    \"rotate_15_cw\": \"rotate_15_cw_21000\",\n",
    "    \"rotate_15_ccw\": \"rotate_15_ccw_21000\"\n",
    "}\n",
    "\n",
    "categories = ['SPIRAL', 'ELLIPTICAL', 'UNCERTAIN', 'MERGER']\n",
    "\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_base, category), exist_ok=True)\n",
    "\n",
    "for aug_name, folder in augmentations.items():\n",
    "    total_copied = {category: 0 for category in categories} \n",
    "\n",
    "    for category in categories:\n",
    "        src_folder = os.path.join(augmented_base_path, folder, category)\n",
    "        dest_folder = os.path.join(output_base, category)\n",
    "\n",
    "        files = [f for f in os.listdir(src_folder) if f.endswith('.jpg')][:1313]\n",
    "\n",
    "        for file_name in files:\n",
    "            shutil.copy(os.path.join(src_folder, file_name), os.path.join(dest_folder, file_name))\n",
    "            total_copied[category] += 1 \n",
    "\n",
    "    print(f\"{aug_name}: {total_copied} файлов скопировано\")\n",
    "\n",
    "final_counts = {category: len(os.listdir(os.path.join(output_base, category))) for category in categories}\n",
    "print(f\"ИТОГОВОЕ РАСПРЕДЕЛЕНИЕ: {final_counts}\")\n",
    "\n",
    "print(\"Создание финальной папки с 42000 изображениями завершено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ec4c7-f98e-4800-ae2b-522685f1a532",
   "metadata": {},
   "source": [
    "# Модель для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c623cc1-7569-42a2-b8e8-45e66cf65107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DATASET_PATH = 'D:/nir/gc/final_mixed_data__with_merge'  \n",
    "MODEL_SAVE_PATH = 'galaxy_classifier_mixed_merge_.keras' \n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Указанная директория '{DATASET_PATH}' не найдена.\")\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    directory=DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  \n",
    "    Dense(4, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "training_time = (end_time - start_time) / 60  \n",
    "print(f\"\\nВремя обучения: {training_time:.2f} минут\")\n",
    "\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator, steps=val_generator.samples // BATCH_SIZE + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1) \n",
    "true_classes = val_generator.classes  \n",
    "class_labels = list(val_generator.class_indices.keys())  \n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"\\nОтчёт о классификации:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"\\nМодель сохранена в {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af8d9b81-3eff-445e-8c8e-718130f2a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "models_3class = {\n",
    "    \"Модель с оригинальными изображениями (3 класса)\": load_model(\"galaxy_classifier_original.keras\"),\n",
    "    \"Модель с оригинальными изображениями + шум (3 класса)\": load_model(\"galaxy_classifier_original_noise.keras\")\n",
    "}\n",
    "\n",
    "models_4class = {\n",
    "    \"Модель с оригинальными изображениями (4 класса)\": load_model(\"galaxy_classifier_merge.keras\"),\n",
    "    \"Модель с оригинальными изображениями + шум (4 класса)\": load_model(\"galaxy_classifier_merge_noise.keras\")\n",
    "}\n",
    "\n",
    "\n",
    "class_labels_3 = ['ELLIPTICAL', 'SPIRAL', 'UNCERTAIN']\n",
    "class_labels_4 = ['ELLIPTICAL', 'MERGER', 'SPIRAL', 'UNCERTAIN']\n",
    "\n",
    "\n",
    "class GalaxyClassifierApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Galaxy Classifier\")\n",
    "        self.root.geometry(\"500x600\")\n",
    "\n",
    "        self.image_label = tk.Label(root)\n",
    "        self.image_label.pack(pady=10)\n",
    "\n",
    "        self.model_type = tk.StringVar(value=\"Модель с оригинальными изображениями (3 класса)\")\n",
    "        self.model_options = list(models_3class.keys()) + list(models_4class.keys())\n",
    "        tk.OptionMenu(root, self.model_type, *self.model_options).pack()\n",
    "\n",
    "        tk.Button(root, text=\"Загрузить изображение\", command=self.load_image).pack(pady=5)\n",
    "        self.result_text = tk.StringVar()\n",
    "        tk.Label(root, textvariable=self.result_text, font=(\"Arial\", 12)).pack(pady=10)\n",
    "\n",
    "    def load_image(self):\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        img = Image.open(file_path).convert('RGB')\n",
    "        img_resized = img.resize((128, 128))\n",
    "        img_array = image.img_to_array(img_resized) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        model_name = self.model_type.get()\n",
    "        if model_name in models_3class:\n",
    "            model = models_3class[model_name]\n",
    "            labels = class_labels_3\n",
    "        else:\n",
    "            model = models_4class[model_name]\n",
    "            labels = class_labels_4\n",
    "\n",
    "        prediction = model.predict(img_array)\n",
    "        class_index = np.argmax(prediction)\n",
    "\n",
    "        self.result_text.set(f\"Предсказанный класс: {labels[class_index]}\")\n",
    "\n",
    " \n",
    "        display_img = img.resize((256, 256))\n",
    "        tk_img = ImageTk.PhotoImage(display_img)\n",
    "        self.image_label.configure(image=tk_img)\n",
    "        self.image_label.image = tk_img\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    app = GalaxyClassifierApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb6361-1bc4-419f-8f53-a1c5936d1a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
